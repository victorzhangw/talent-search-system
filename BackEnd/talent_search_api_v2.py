#!/usr/bin/env python3
"""
äººæ‰èŠå¤©æœç´¢ API v2.0
ä¿®æ­£ç‰ˆï¼šä½¿ç”¨æ­£ç¢ºçš„ test_project_result è¡¨
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import psycopg2
from sshtunnel import SSHTunnelForwarder
import json
from datetime import datetime
import os
import uvicorn
import httpx
import asyncio
from interview_api import router as interview_router
from talent_analysis_service import TalentAnalysisService
from conversation_manager import conversation_manager

# è³‡æ–™åº«é€£æ¥é…ç½®
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PRIVATE_KEY_PATH = os.path.join(SCRIPT_DIR, 'private-key-openssh.pem')

DB_CONFIG = {
    'ssh_host': '54.199.255.239',
    'ssh_port': 22,
    'ssh_username': 'victor_cheng',
    'ssh_private_key': PRIVATE_KEY_PATH,
    'db_host': 'localhost',
    'db_port': 5432,
    'db_name': 'projectdb',
    'db_user': 'projectuser',
    'db_password': 'projectpass'
}

# LLM API é…ç½®
LLM_CONFIG = {
    'api_key': 'sk-xmwxrtsxgsjwuyeceydoyuopezzlqresdjyvlzrbbjeejiff',
    'api_host': 'https://api.siliconflow.cn',
    'model': 'deepseek-ai/DeepSeek-V3',
    'endpoint': 'https://api.siliconflow.cn/v1/chat/completions'
}

# FastAPI æ‡‰ç”¨
app = FastAPI(title="äººæ‰èŠå¤©æœç´¢ API v2.0", version="2.0.0")

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åŒ…å«é¢è©¦å•é¡Œè·¯ç”±
app.include_router(interview_router)

# å…¨åŸŸè®Šæ•¸
tunnel = None
db_conn = None
trait_cache = {}  # ç·©å­˜ç‰¹è³ªå®šç¾©

# è³‡æ–™æ¨¡å‹
class SearchQuery(BaseModel):
    query: str
    session_id: Optional[str] = None
    filters: Optional[Dict[str, Any]] = None
    previous_candidate_ids: Optional[List[int]] = None  # ä¸Šä¸€è¼ªçš„å€™é¸äºº ID åˆ—è¡¨

class Candidate(BaseModel):
    id: int
    name: str
    email: str
    phone: Optional[str] = None
    company: Optional[str] = None
    position: Optional[str] = None
    test_results: List[Dict[str, Any]] = []
    trait_results: Optional[Dict[str, Any]] = {}
    match_score: float
    match_reason: str
    ai_analysis: Optional[Dict[str, Any]] = None  # æ–°å¢ AI åˆ†æçµæœ

class SearchResponse(BaseModel):
    candidates: List[Candidate]
    total: int
    query_understanding: str
    suggestions: List[str]

# è³‡æ–™åº«é€£æ¥ç®¡ç†
def get_db_connection():
    """å–å¾—è³‡æ–™åº«é€£æ¥"""
    global tunnel, db_conn
    
    if db_conn is None or db_conn.closed:
        if tunnel is None or not tunnel.is_active:
            tunnel = SSHTunnelForwarder(
                (DB_CONFIG['ssh_host'], DB_CONFIG['ssh_port']),
                ssh_username=DB_CONFIG['ssh_username'],
                ssh_pkey=DB_CONFIG['ssh_private_key'],
                remote_bind_address=(DB_CONFIG['db_host'], DB_CONFIG['db_port'])
            )
            tunnel.start()
        
        db_conn = psycopg2.connect(
            host='localhost',
            port=tunnel.local_bind_port,
            database=DB_CONFIG['db_name'],
            user=DB_CONFIG['db_user'],
            password=DB_CONFIG['db_password']
        )
    
    return db_conn

def load_trait_definitions():
    """è¼‰å…¥ç‰¹è³ªå®šç¾©åˆ°ç·©å­˜"""
    global trait_cache
    
    if trait_cache:
        return trait_cache
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT id, chinese_name, system_name, description
        FROM trait
        ORDER BY id;
    """)
    
    for row in cursor.fetchall():
        trait_id, chinese_name, system_name, description = row
        trait_cache[system_name] = {
            'id': trait_id,
            'chinese_name': chinese_name,
            'system_name': system_name,
            'description': description
        }
    
    cursor.close()
    print(f"âœ“ è¼‰å…¥ {len(trait_cache)} å€‹ç‰¹è³ªå®šç¾©")
    return trait_cache

def enrich_trait_results(trait_results: Dict) -> Dict:
    """è±å¯Œç‰¹è³ªçµæœï¼Œæ·»åŠ ä¸­æ–‡åç¨±å’Œæè¿°"""
    if not trait_results:
        return {}
    
    traits = load_trait_definitions()
    enriched = {}
    
    for trait_key, trait_data in trait_results.items():
        # trait_key æ˜¯ trait_results ä¸­çš„ key (å¦‚ "Hope", "Creative Thinking")
        # éœ€è¦å¾ trait è¡¨ä¸­æŸ¥æ‰¾å°æ‡‰çš„ä¸­æ–‡åç¨±
        
        if trait_key in traits:
            # æ‰¾åˆ°å°æ‡‰çš„ç‰¹è³ªå®šç¾©
            trait_def = traits[trait_key]
            
            if isinstance(trait_data, dict):
                enriched[trait_key] = {
                    **trait_data,
                    'chinese_name': trait_def['chinese_name'],
                    'description': trait_def['description']
                }
            else:
                enriched[trait_key] = {
                    'score': trait_data,
                    'chinese_name': trait_def['chinese_name'],
                    'description': trait_def['description']
                }
        else:
            # å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰çš„ç‰¹è³ªå®šç¾©ï¼Œä¿ç•™åŸå§‹æ•¸æ“š
            if isinstance(trait_data, dict):
                enriched[trait_key] = trait_data
            else:
                enriched[trait_key] = {'score': trait_data, 'chinese_name': trait_key}
    
    return enriched

# LLM æœå‹™
class LLMService:
    """LLM æœå‹™ - æ™ºèƒ½æŸ¥è©¢åˆ†æ"""
    
    def __init__(self):
        self.api_key = LLM_CONFIG['api_key']
        self.api_endpoint = LLM_CONFIG['endpoint']
        self.model = LLM_CONFIG['model']
        self.available_traits = list(trait_cache.values())
    
    def get_trait_analysis_prompt(self) -> str:
        """ç”Ÿæˆç‰¹è³ªåˆ†æ Prompt"""
        traits_list = []
        for trait in self.available_traits[:50]:  # æ‰€æœ‰ 50 å€‹ç‰¹è³ª
            traits_list.append(
                f"- {trait['chinese_name']} ({trait['system_name']}): {trait['description']}"
            )
        
        traits_text = '\n'.join(traits_list)
        
        return f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„äººæ‰æœç´¢åŠ©æ‰‹ã€‚

ç”¨æˆ¶æœƒç”¨è‡ªç„¶èªè¨€æè¿°ä»–å€‘éœ€è¦çš„äººæ‰ï¼Œä½ éœ€è¦ï¼š
1. ç†è§£ç”¨æˆ¶çš„éœ€æ±‚
2. å¾ä»¥ä¸‹ç‰¹è³ªåˆ—è¡¨ä¸­ï¼Œé¸æ“‡æœ€åŒ¹é…çš„ 1-3 å€‹ç‰¹è³ª
3. ç‚ºæ¯å€‹ç‰¹è³ªè¨­å®šæœ€ä½åˆ†æ•¸è¦æ±‚ï¼ˆ0-100ï¼‰

**å¯ç”¨çš„ç‰¹è³ªåˆ—è¡¨**ï¼š
{traits_text}

è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼š
{{
  "matched_traits": [
    {{
      "system_name": "ç‰¹è³ªç³»çµ±åç¨±",
      "chinese_name": "ç‰¹è³ªä¸­æ–‡åç¨±",
      "min_score": 70,
      "reason": "ç‚ºä»€éº¼é¸æ“‡é€™å€‹ç‰¹è³ª"
    }}
  ],
  "summary": "éœ€æ±‚æ‘˜è¦",
  "understanding": "å°ç”¨æˆ¶éœ€æ±‚çš„ç†è§£"
}}

**é‡è¦è¦å‰‡**ï¼š
1. åªé¸æ“‡ 1-3 å€‹æœ€ç›¸é—œçš„ç‰¹è³ª
2. min_score é€šå¸¸è¨­å®šç‚º 70-80 åˆ†
3. å¦‚æœç”¨æˆ¶éœ€æ±‚æ¨¡ç³Šï¼Œé¸æ“‡æœ€å¯èƒ½çš„ç‰¹è³ª
4. åªè¼¸å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—"""
    
    async def analyze_query(self, query: str) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM åˆ†ææŸ¥è©¢"""
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    self.api_endpoint,
                    headers={
                        'Content-Type': 'application/json',
                        'Authorization': f'Bearer {self.api_key}'
                    },
                    json={
                        'model': self.model,
                        'messages': [
                            {
                                'role': 'system',
                                'content': self.get_trait_analysis_prompt()
                            },
                            {
                                'role': 'user',
                                'content': f'è«‹åˆ†æä»¥ä¸‹äººæ‰éœ€æ±‚ï¼š\n\n{query}'
                            }
                        ],
                        'temperature': 0.3,
                        'max_tokens': 1000,
                        'response_format': {'type': 'json_object'}
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    analysis = json.loads(content)
                    
                    print(f"\nğŸ¤– LLM åˆ†æçµæœ:")
                    print(f"   ç†è§£: {analysis.get('understanding', '')}")
                    print(f"   åŒ¹é…ç‰¹è³ª: {len(analysis.get('matched_traits', []))} å€‹")
                    for trait in analysis.get('matched_traits', []):
                        print(f"     â€¢ {trait['chinese_name']} ({trait['system_name']}) >= {trait['min_score']}")
                    
                    return {
                        'success': True,
                        'analysis': analysis
                    }
                else:
                    print(f"âŒ LLM API éŒ¯èª¤: {response.status_code}")
                    return {'success': False, 'error': 'LLM API éŒ¯èª¤'}
        
        except Exception as e:
            print(f"âŒ LLM åˆ†æéŒ¯èª¤: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def generate_match_reason(self, candidate: Dict, query: str, matched_traits: List[Dict]) -> str:
        """ç”ŸæˆåŒ¹é…ç†ç”±"""
        trait_results = candidate.get('trait_results', {})
        
        # æå–åŒ¹é…çš„ç‰¹è³ªåˆ†æ•¸
        matched_scores = []
        for trait in matched_traits:
            system_name = trait['system_name']
            if system_name in trait_results:
                trait_data = trait_results[system_name]
                if isinstance(trait_data, dict):
                    score = trait_data.get('score', 0)
                    chinese_name = trait_data.get('chinese_name', trait['chinese_name'])
                    matched_scores.append(f"{chinese_name}({score:.0f}åˆ†)")
        
        if matched_scores:
            return f"åŒ¹é…ç‰¹è³ªï¼š{', '.join(matched_scores)}"
        else:
            return f"å·²å®Œæˆ {len(trait_results)} é …ç‰¹è³ªæ¸¬è©•"

# äººæ‰æœç´¢å¼•æ“
class TalentSearchEngine:
    """äººæ‰æœç´¢å¼•æ“ - ä½¿ç”¨ test_project_result + LLM æ™ºèƒ½æœç´¢"""
    
    def __init__(self):
        self.conn = get_db_connection()
        load_trait_definitions()
        self.llm_service = LLMService()
    
    def filter_candidates_by_traits(self, candidates: List[Dict], matched_traits: List[Dict]) -> List[Dict]:
        """
        å¾æŒ‡å®šçš„å€™é¸äººåˆ—è¡¨ä¸­ï¼Œæ ¹æ“šç‰¹è³ªç¯©é¸
        
        Args:
            candidates: å€™é¸äººåˆ—è¡¨
            matched_traits: åŒ¹é…çš„ç‰¹è³ªæ¢ä»¶
            
        Returns:
            ç¯©é¸å¾Œçš„å€™é¸äººåˆ—è¡¨
        """
        filtered = []
        
        print(f"\nğŸ” å¾ {len(candidates)} ä½å€™é¸äººä¸­ç¯©é¸...")
        print(f"   ç¯©é¸æ¢ä»¶: {len(matched_traits)} å€‹ç‰¹è³ª")
        
        for candidate in candidates:
            trait_results = candidate.get('trait_results', {})
            
            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆä»»ä¸€ç‰¹è³ªæ¢ä»¶
            matches_any = False
            for trait in matched_traits:
                system_name = trait['system_name']
                min_score = trait['min_score']
                
                if system_name in trait_results:
                    trait_data = trait_results[system_name]
                    if isinstance(trait_data, dict):
                        score = trait_data.get('score', 0)
                        if score >= min_score:
                            matches_any = True
                            break
            
            if matches_any:
                filtered.append(candidate)
        
        print(f"âœ“ ç¯©é¸å¾Œå‰©é¤˜ {len(filtered)} ä½å€™é¸äºº")
        return filtered
    
    def get_all_candidates(self, limit: int = 50) -> List[Dict]:
        """ç²å–æ‰€æœ‰å€™é¸äºº - ä½¿ç”¨ test_project_result"""
        cursor = self.conn.cursor()
        
        sql = """
            SELECT 
                tiv.id,
                tiv.name,
                tiv.email,
                tiv.phone,
                tiv.company,
                tiv.position,
                tp.name as project_name,
                tpr.trait_results,
                tpr.category_results,
                tpr.score_value,
                tpr.prediction_value,
                tpr.crawled_at
            FROM test_project_result tpr
            INNER JOIN test_invitation ti ON tpr.test_invitation_id = ti.id
            INNER JOIN test_invitee tiv ON ti.invitee_id = tiv.id
            INNER JOIN test_project tp ON tpr.test_project_id = tp.id
            WHERE tpr.trait_results IS NOT NULL
              AND tpr.trait_results != '{}'::jsonb
            ORDER BY tpr.crawled_at DESC
            LIMIT %s;
        """
        
        print(f"\nğŸ” åŸ·è¡ŒæŸ¥è©¢: get_all_candidates (limit={limit})")
        cursor.execute(sql, (limit,))
        results = cursor.fetchall()
        print(f"âœ“ æŸ¥è©¢è¿”å› {len(results)} ç­†è¨˜éŒ„")
        
        candidates = []
        for row in results:
            # è±å¯Œç‰¹è³ªçµæœï¼Œæ·»åŠ ä¸­æ–‡åç¨±
            trait_results = enrich_trait_results(row[7] if row[7] else {})
            
            candidate = {
                'id': row[0],
                'name': row[1],
                'email': row[2],
                'phone': row[3],
                'company': row[4],
                'position': row[5],
                'project_name': row[6],
                'trait_results': trait_results,
                'category_results': row[8] if row[8] else {},
                'score_value': row[9],
                'prediction_value': row[10],
                'test_date': row[11].isoformat() if row[11] else None
            }
            candidates.append(candidate)
            
            print(f"  å€™é¸äºº {row[1]}: {len(trait_results)} å€‹ç‰¹è³ª")
        
        cursor.close()
        return candidates
    
    def search_by_multiple_traits(self, matched_traits: List[Dict], limit: int = 50, previous_candidate_ids: Optional[List[int]] = None) -> List[Dict]:
        """æ ¹æ“šå¤šå€‹ç‰¹è³ªæœç´¢å€™é¸äºº"""
        cursor = self.conn.cursor()
        
        # æ§‹å»º WHERE æ¢ä»¶
        where_conditions = []
        params = []
        
        for trait in matched_traits:
            system_name = trait['system_name']
            min_score = trait['min_score']
            where_conditions.append(
                f"(tpr.trait_results->%s->>'score')::float >= %s"
            )
            params.extend([system_name, min_score])
        
        where_clause = ' OR '.join(where_conditions)
        
        # å¦‚æœæœ‰ä¸Šä¸€è¼ªçš„å€™é¸äºº IDï¼Œåªåœ¨é€™äº›å€™é¸äººä¸­æœç´¢
        if previous_candidate_ids:
            where_clause = f"({where_clause}) AND tiv.id = ANY(%s)"
            params.append(previous_candidate_ids)
        
        sql = f"""
            SELECT 
                tiv.id,
                tiv.name,
                tiv.email,
                tiv.phone,
                tiv.company,
                tiv.position,
                tp.name as project_name,
                tpr.trait_results,
                tpr.category_results,
                tpr.score_value,
                tpr.prediction_value,
                tpr.crawled_at
            FROM test_project_result tpr
            INNER JOIN test_invitation ti ON tpr.test_invitation_id = ti.id
            INNER JOIN test_invitee tiv ON ti.invitee_id = tiv.id
            INNER JOIN test_project tp ON tpr.test_project_id = tp.id
            WHERE tpr.trait_results IS NOT NULL
              AND tpr.trait_results != '{{}}'::jsonb
              AND ({where_clause})
            ORDER BY tpr.crawled_at DESC
            LIMIT %s;
        """
        
        params.append(limit)
        
        print(f"\nğŸ“Š åŸ·è¡Œç‰¹è³ªæœç´¢:")
        for trait in matched_traits:
            print(f"   â€¢ {trait['chinese_name']} >= {trait['min_score']}")
        
        cursor.execute(sql, params)
        results = cursor.fetchall()
        
        print(f"âœ“ æ‰¾åˆ° {len(results)} ä½ç¬¦åˆæ¢ä»¶çš„å€™é¸äºº")
        
        candidates = []
        for row in results:
            trait_results = enrich_trait_results(row[7] if row[7] else {})
            
            candidate = {
                'id': row[0],
                'name': row[1],
                'email': row[2],
                'phone': row[3],
                'company': row[4],
                'position': row[5],
                'project_name': row[6],
                'trait_results': trait_results,
                'category_results': row[8] if row[8] else {},
                'score_value': row[9],
                'prediction_value': row[10],
                'test_date': row[11].isoformat() if row[11] else None
            }
            candidates.append(candidate)
        
        cursor.close()
        return candidates
    
    async def smart_search(self, query: str, limit: int = 50, previous_candidate_ids: Optional[List[int]] = None) -> Dict[str, Any]:
        """æ™ºèƒ½æœç´¢ - ä½¿ç”¨ LLM åˆ†ææŸ¥è©¢ä¸¦æœç´¢åŒ¹é…çš„å€™é¸äºº"""
        print(f"\nğŸ” æ™ºèƒ½æœç´¢: {query}")
        
        # å¦‚æœæœ‰ä¸Šä¸€è¼ªçš„å€™é¸äºº IDï¼Œé¡¯ç¤ºç¯©é¸è³‡è¨Š
        if previous_candidate_ids:
            print(f"   ğŸ“Œ åœ¨ {len(previous_candidate_ids)} ä½å€™é¸äººä¸­é€²è¡Œç¯©é¸")
        
        # 1. ä½¿ç”¨ LLM åˆ†ææŸ¥è©¢
        llm_result = await self.llm_service.analyze_query(query)
        
        if not llm_result['success']:
            print("âš ï¸ LLM åˆ†æå¤±æ•—ï¼Œè¿”å›æ‰€æœ‰å€™é¸äºº")
            candidates = self.get_all_candidates(limit)
            for candidate in candidates:
                candidate['match_score'] = self.calculate_match_score(candidate, query)
                candidate['match_reason'] = self.generate_match_reason(candidate, candidate['match_score'])
            return {
                'candidates': candidates,
                'total': len(candidates),
                'analysis': {
                    'understanding': f"æ‰¾åˆ° {len(candidates)} ä½å€™é¸äºº",
                    'matched_traits': []
                },
                'matched_traits': []
            }
        
        analysis = llm_result['analysis']
        matched_traits = analysis.get('matched_traits', [])
        
        if not matched_traits:
            print("âš ï¸ æ²’æœ‰åŒ¹é…çš„ç‰¹è³ªï¼Œè¿”å›æ‰€æœ‰å€™é¸äºº")
            if previous_candidate_ids:
                # å¦‚æœæœ‰ä¸Šä¸€è¼ªçµæœï¼Œè¿”å›é€™äº›å€™é¸äºº
                candidates = self.get_candidates_by_ids(previous_candidate_ids)
            else:
                candidates = self.get_all_candidates(limit)
            for candidate in candidates:
                candidate['match_score'] = self.calculate_match_score(candidate, query)
                candidate['match_reason'] = self.generate_match_reason(candidate, candidate['match_score'])
            return {
                'candidates': candidates,
                'total': len(candidates),
                'analysis': analysis,
                'matched_traits': [],
                'is_refinement': previous_candidate_ids is not None
            }
        
        # 2. æ ¹æ“šåŒ¹é…çš„ç‰¹è³ªæœç´¢å€™é¸äººï¼ˆåœ¨ä¸Šä¸€è¼ªçµæœä¸­ç¯©é¸ï¼‰
        candidates = self.search_by_multiple_traits(matched_traits, limit, previous_candidate_ids)
        
        # 3. è¨ˆç®—åŒ¹é…åˆ†æ•¸
        for candidate in candidates:
            candidate['match_score'] = self.calculate_trait_match_score(
                candidate, matched_traits
            )
            candidate['match_reason'] = await self.llm_service.generate_match_reason(
                candidate, query, matched_traits
            )
        
        # 4. æŒ‰åŒ¹é…åˆ†æ•¸æ’åº
        candidates.sort(key=lambda x: x['match_score'], reverse=True)
        
        return {
            'candidates': candidates,
            'total': len(candidates),
            'analysis': analysis,
            'matched_traits': matched_traits,
            'is_refinement': previous_candidate_ids is not None
        }
    
    def calculate_trait_match_score(self, candidate: Dict, matched_traits: List[Dict]) -> float:
        """æ ¹æ“šåŒ¹é…ç‰¹è³ªè¨ˆç®—åˆ†æ•¸ï¼ˆæ­¸ä¸€åŒ–åˆ° 0-1ï¼‰"""
        trait_results = candidate.get('trait_results', {})
        
        if not trait_results or not matched_traits:
            return 0.1
        
        total_score = 0
        matched_count = 0
        
        for trait in matched_traits:
            system_name = trait['system_name']
            min_score = trait['min_score']
            
            if system_name in trait_results:
                trait_data = trait_results[system_name]
                if isinstance(trait_data, dict):
                    score = trait_data.get('score', 0)
                    if score >= min_score:
                        # è¨ˆç®—è©²ç‰¹è³ªçš„æ¨™æº–åŒ–åˆ†æ•¸
                        # ä½¿ç”¨å€™é¸äººåˆ†æ•¸ç›´æ¥é™¤ä»¥ 100ï¼Œç¢ºä¿åœ¨ 0-1 ç¯„åœå…§
                        normalized_score = min(score / 100, 1.0)
                        
                        # è¶…éæœ€ä½è¦æ±‚çµ¦äºˆé¡å¤–æ¬Šé‡ï¼ˆä½†ä¿æŒåœ¨åˆç†ç¯„åœï¼‰
                        if score > min_score:
                            # é¡å¤–çå‹µæœ€å¤š 0.2ï¼ˆ20%ï¼‰
                            bonus = min((score - min_score) / 100 * 0.5, 0.2)
                            normalized_score = min(normalized_score + bonus, 1.0)
                        
                        total_score += normalized_score
                        matched_count += 1
        
        if matched_count > 0:
            # è¨ˆç®—å¹³å‡åˆ†æ•¸ï¼Œç¢ºä¿çµæœåœ¨ 0-1 ä¹‹é–“
            avg_score = total_score / matched_count
            return min(max(avg_score, 0.0), 1.0)
        else:
            return 0.1
    
    def calculate_match_score(self, candidate: Dict, query: str) -> float:
        """è¨ˆç®—åŒ¹é…åˆ†æ•¸"""
        trait_results = candidate.get('trait_results', {})
        
        if not trait_results:
            return 0.1
        
        # è¨ˆç®—å¹³å‡åˆ†æ•¸
        scores = []
        for trait_data in trait_results.values():
            if isinstance(trait_data, dict) and 'score' in trait_data:
                scores.append(trait_data['score'])
        
        if scores:
            avg_score = sum(scores) / len(scores)
            return avg_score / 100  # è½‰æ›ç‚º 0-1
        
        return 0.5
    
    def generate_match_reason(self, candidate: Dict, score: float) -> str:
        """ç”ŸæˆåŒ¹é…ç†ç”±"""
        trait_results = candidate.get('trait_results', {})
        
        if not trait_results:
            return "å°šæœªå®Œæˆæ¸¬è©•"
        
        # æ‰¾å‡ºé«˜åˆ†ç‰¹è³ª
        high_traits = []
        for trait_key, trait_data in trait_results.items():
            if isinstance(trait_data, dict):
                trait_score = trait_data.get('score', 0)
                chinese_name = trait_data.get('chinese_name', trait_key)
                if trait_score >= 75:
                    high_traits.append(f"{chinese_name}({int(trait_score)}åˆ†)")
        
        if high_traits:
            return f"å„ªå‹¢ç‰¹è³ªï¼š{', '.join(high_traits[:3])}"
        else:
            return f"å·²å®Œæˆ {len(trait_results)} é …ç‰¹è³ªæ¸¬è©•"

# API ç«¯é»
@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•æ™‚åˆå§‹åŒ–"""
    print("æ­£åœ¨åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥...")
    get_db_connection()
    load_trait_definitions()
    print("âœ“ è³‡æ–™åº«é€£æ¥å®Œæˆï¼")
    print("âœ“ ç‰¹è³ªå®šç¾©è¼‰å…¥å®Œæˆï¼")
    print("âœ“ LLM æ™ºèƒ½æœç´¢å·²å•Ÿç”¨ï¼")
    print("âœ“ åˆå§‹åŒ–å®Œæˆï¼")

@app.on_event("shutdown")
async def shutdown_event():
    """æ‡‰ç”¨é—œé–‰æ™‚æ¸…ç†è³‡æº"""
    global tunnel, db_conn
    if db_conn:
        db_conn.close()
    if tunnel:
        tunnel.stop()
    print("è³‡æºå·²æ¸…ç†")

@app.get("/")
async def root():
    """æ ¹è·¯å¾‘"""
    return {
        "message": "äººæ‰èŠå¤©æœç´¢ API v2.1 - æ™ºèƒ½æœç´¢ç‰ˆ",
        "version": "2.1.0",
        "features": [
            "ğŸ¤– LLM æ™ºèƒ½æŸ¥è©¢åˆ†æ",
            "ğŸ¯ æ ¹æ“šç‰¹è³ªç²¾æº–åŒ¹é…",
            "ğŸ“Š ä½¿ç”¨ test_project_result è¡¨ï¼ˆ27 ç­†æ•¸æ“šï¼‰",
            "ğŸ‡¨ğŸ‡³ æ•´åˆ trait è¡¨é¡¯ç¤ºä¸­æ–‡åç¨±",
            "ğŸ“ˆ æ™ºèƒ½åŒ¹é…åˆ†æ•¸è¨ˆç®—",
            "ğŸ” å¤šç‰¹è³ªçµ„åˆæœç´¢"
        ],
        "endpoints": {
            "search": "/api/search - æ™ºèƒ½æœç´¢ï¼ˆä½¿ç”¨ LLMï¼‰",
            "candidates": "/api/candidates - ç²å–æ‰€æœ‰å€™é¸äºº",
            "traits": "/api/traits - ç²å–ç‰¹è³ªåˆ—è¡¨",
            "health": "/health - å¥åº·æª¢æŸ¥"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        cursor.close()
        
        return {
            "status": "healthy",
            "database": "connected",
            "traits_loaded": len(trait_cache),
            "llm_enabled": True,
            "version": "2.1.0"
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }

@app.post("/api/search", response_model=SearchResponse)
async def search_talents(query: SearchQuery):
    """æ™ºèƒ½æœç´¢äººæ‰ - ä½¿ç”¨ LLM åˆ†ææŸ¥è©¢ï¼ˆæ”¯æ´å¤šè¼ªå°è©±ï¼‰"""
    try:
        # ç¢ºä¿æŸ¥è©¢å­—ç¬¦ä¸²æ­£ç¢ºç·¨ç¢¼
        query_text = query.query
        session_id = query.session_id or "default"
        
        print(f"\nğŸ“ æ”¶åˆ°æŸ¥è©¢: {query_text}")
        print(f"   æœƒè©± ID: {session_id}")
        print(f"   æŸ¥è©¢é•·åº¦: {len(query_text)} å­—ç¬¦")
        
        # ç²å–æˆ–å‰µå»ºæœƒè©±ä¸Šä¸‹æ–‡
        context = conversation_manager.get_or_create_session(session_id)
        context.add_message('user', query_text)
        context.last_query = query_text
        
        # åˆ†æä¸Šä¸‹æ–‡æ„åœ–
        context_analysis = conversation_manager.analyze_context_intent(context, query_text)
        
        print(f"   ä¸Šä¸‹æ–‡åˆ†æ: {context_analysis.get('is_follow_up', False)}")
        if context_analysis.get('is_follow_up'):
            print(f"   å¾ŒçºŒæ„åœ–: {context_analysis.get('follow_up_intent')}")
        
        engine = TalentSearchEngine()
        
        # è™•ç†å¾ŒçºŒå•é¡Œ
        if context_analysis.get('is_follow_up'):
            follow_up_intent = context_analysis.get('follow_up_intent')
            scope = context_analysis.get('scope', 'all')
            
            # è™•ç†å¾ç•¶å‰çµæœä¸­ç¯©é¸
            if follow_up_intent == 'filter_from_current' and scope == 'current':
                current_candidates = context.current_candidates
                previous_count = context_analysis.get('previous_count', len(current_candidates))
                
                if current_candidates:
                    print(f"\nğŸ“Š æ¼¸é€²å¼ç¯©é¸æ¨¡å¼")
                    print(f"   ç•¶å‰å€™é¸äººæ•¸: {len(current_candidates)}")
                    print(f"   æ–°ç¯©é¸æ¢ä»¶: {query_text}")
                    
                    # ä½¿ç”¨ LLM åˆ†ææ–°çš„ç¯©é¸æ¢ä»¶
                    llm_result = await engine.llm_service.analyze_query(query_text)
                    
                    if llm_result['success']:
                        analysis = llm_result['analysis']
                        matched_traits = analysis.get('matched_traits', [])
                        
                        if matched_traits:
                            # å¾ç•¶å‰å€™é¸äººä¸­ç¯©é¸
                            filtered_candidates = engine.filter_candidates_by_traits(
                                current_candidates,
                                matched_traits
                            )
                            
                            # è¨ˆç®—åŒ¹é…åˆ†æ•¸
                            for candidate in filtered_candidates:
                                candidate['match_score'] = engine.calculate_trait_match_score(
                                    candidate, matched_traits
                                )
                                candidate['match_reason'] = await engine.llm_service.generate_match_reason(
                                    candidate, query_text, matched_traits
                                )
                            
                            # æŒ‰åˆ†æ•¸æ’åº
                            filtered_candidates.sort(key=lambda x: x['match_score'], reverse=True)
                            
                            search_result = {
                                'candidates': filtered_candidates,
                                'total': len(filtered_candidates),
                                'analysis': analysis,
                                'matched_traits': matched_traits,
                                'filter_mode': 'progressive',
                                'previous_count': previous_count
                            }
                        else:
                            # æ²’æœ‰åŒ¹é…çš„ç‰¹è³ªï¼Œè¿”å›ç•¶å‰åˆ—è¡¨
                            search_result = {
                                'candidates': current_candidates,
                                'total': len(current_candidates),
                                'analysis': analysis,
                                'matched_traits': [],
                                'filter_mode': 'none'
                            }
                    else:
                        # LLM åˆ†æå¤±æ•—ï¼Œè¿”å›ç•¶å‰åˆ—è¡¨
                        search_result = {
                            'candidates': current_candidates,
                            'total': len(current_candidates),
                            'analysis': {'understanding': 'ç„¡æ³•åˆ†æç¯©é¸æ¢ä»¶'},
                            'matched_traits': [],
                            'filter_mode': 'none'
                        }
                else:
                    # æ²’æœ‰ç•¶å‰åˆ—è¡¨ï¼ŒåŸ·è¡Œæ–°æœç´¢
                    print("âš ï¸ æ²’æœ‰ç•¶å‰å€™é¸äººåˆ—è¡¨ï¼ŒåŸ·è¡Œæ–°æœç´¢")
                    search_result = await engine.smart_search(query_text, limit=50)
            
            # è™•ç†æ–°æœç´¢æ„åœ–
            elif follow_up_intent == 'new_search':
                print(f"\nğŸ”„ æ–°æœç´¢æ¨¡å¼ï¼ˆæ¸…ç©ºä¹‹å‰çš„çµæœï¼‰")
                search_result = await engine.smart_search(query_text, limit=50)
            
            # å…¶ä»–å¾ŒçºŒå•é¡Œï¼ŒåŸ·è¡Œæ–°æœç´¢
            else:
                search_result = await engine.smart_search(query_text, limit=50)
        else:
            # æ–°æŸ¥è©¢ï¼ŒåŸ·è¡Œæ™ºèƒ½æœç´¢
            print(f"\nğŸ†• æ–°æœç´¢æ¨¡å¼")
            search_result = await engine.smart_search(query_text, limit=50)
        
        raw_candidates = search_result['candidates']
        analysis = search_result['analysis']
        matched_traits = search_result['matched_traits']
        
        # æ›´æ–°æœƒè©±ä¸Šä¸‹æ–‡
        context.set_current_candidates(raw_candidates)
        if len(raw_candidates) == 1:
            context.set_current_candidate(raw_candidates[0])
        
        # è½‰æ›ç‚º Candidate ç‰©ä»¶
        candidates = []
        for c in raw_candidates:
            candidates.append(Candidate(
                id=c['id'],
                name=c['name'],
                email=c['email'],
                phone=c.get('phone'),
                company=c.get('company'),
                position=c.get('position'),
                test_results=[],
                trait_results=c.get('trait_results', {}),
                match_score=c.get('match_score', 0.5),
                match_reason=c.get('match_reason', 'å·²å®Œæˆæ¸¬è©•')
            ))
        
        # ç”ŸæˆæŸ¥è©¢ç†è§£ï¼ˆæ ¹æ“šç¯©é¸æ¨¡å¼ï¼‰
        filter_mode = search_result.get('filter_mode', 'none')
        previous_count = search_result.get('previous_count', 0)
        
        if filter_mode == 'progressive':
            # æ¼¸é€²å¼ç¯©é¸
            trait_names = [t['chinese_name'] for t in matched_traits]
            understanding = f"å¾ {previous_count} ä½å€™é¸äººä¸­ç¯©é¸å‡º {len(candidates)} ä½ç¬¦åˆã€Œ{', '.join(trait_names)}ã€æ¢ä»¶çš„å€™é¸äºº"
        elif matched_traits:
            # æ–°æœç´¢ï¼ˆæœ‰ç‰¹è³ªåŒ¹é…ï¼‰
            trait_names = [t['chinese_name'] for t in matched_traits]
            understanding = f"æ‚¨æ­£åœ¨å°‹æ‰¾ï¼š{', '.join(trait_names)} å„ªç§€çš„äººæ‰ã€‚æ‰¾åˆ° {len(candidates)} ä½ç¬¦åˆæ¢ä»¶çš„å€™é¸äºº"
        else:
            # æ–°æœç´¢ï¼ˆç„¡ç‰¹è³ªåŒ¹é…ï¼‰
            understanding = analysis.get('understanding', f"æ‰¾åˆ° {len(candidates)} ä½å€™é¸äºº")
        
        # ç”Ÿæˆæ™ºèƒ½å»ºè­°ï¼ˆåŸºæ–¼ä¸Šä¸‹æ–‡å’Œç¯©é¸æ¨¡å¼ï¼‰
        suggestions = []
        
        if filter_mode == 'progressive' and len(candidates) > 0:
            # æ¼¸é€²å¼ç¯©é¸å¾Œçš„å»ºè­°
            suggestions.append("å¾é€™äº›äººä¸­å†ç¯©é¸")
            suggestions.append("é‡æ–°æœç´¢ï¼ˆæ¸…ç©ºç¯©é¸ï¼‰")
            if len(candidates) > 1:
                suggestions.append("æ¯”è¼ƒé€™äº›å€™é¸äºº")
        elif len(candidates) > 1:
            # å¤šå€‹å€™é¸äººçš„å»ºè­°
            suggestions.append("å¾é€™äº›äººä¸­å†ç¯©é¸")
            suggestions.append("æ’é™¤æŸäº›å€™é¸äºº")
            suggestions.append("æ¯”è¼ƒé€™äº›å€™é¸äºº")
        elif len(candidates) == 1:
            # å–®å€‹å€™é¸äººçš„å»ºè­°
            suggestions.append(f"å‘Šè¨´æˆ‘æ›´å¤šé—œæ–¼ {candidates[0].name} çš„è³‡è¨Š")
            suggestions.append("æ‰¾é¡ä¼¼çš„å€™é¸äºº")
        
        if len(candidates) > 0:
            suggestions.extend([
                "æŸ¥çœ‹å€™é¸äººè©³ç´°è³‡æ–™",
                "ç‚ºå€™é¸äººæº–å‚™é¢è©¦å•é¡Œ"
            ])
        
        if matched_traits and filter_mode != 'progressive':
            suggestions.insert(0, f"å·²æ ¹æ“š {len(matched_traits)} å€‹ç‰¹è³ªé€²è¡Œæ™ºèƒ½åŒ¹é…")
        
        # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°ä¸Šä¸‹æ–‡
        context.add_message('assistant', understanding)
        
        # è¿”å›æ‰€æœ‰æ‰¾åˆ°çš„å€™é¸äºº
        return SearchResponse(
            candidates=candidates,
            total=len(candidates),
            query_understanding=understanding,
            suggestions=suggestions
        )
    
    except Exception as e:
        print(f"æœç´¢éŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/candidates")
async def get_candidates(limit: int = 20):
    """ç²å–å€™é¸äººåˆ—è¡¨"""
    try:
        engine = TalentSearchEngine()
        candidates = engine.get_all_candidates(limit=limit)
        
        return {
            "candidates": candidates,
            "total": len(candidates),
            "message": f"æˆåŠŸç²å– {len(candidates)} ä½å€™é¸äºº"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/traits")
async def get_traits():
    """ç²å–æ‰€æœ‰ç‰¹è³ªå®šç¾©"""
    try:
        traits = load_trait_definitions()
        
        return {
            "traits": list(traits.values()),
            "total": len(traits),
            "message": f"å…±æœ‰ {len(traits)} å€‹ç‰¹è³ªå®šç¾©"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/traits/{trait_name}")
async def search_by_trait(trait_name: str, min_score: float = 70):
    """æŒ‰ç‰¹è³ªæœç´¢å€™é¸äºº"""
    try:
        engine = TalentSearchEngine()
        candidates = engine.search_by_trait(trait_name, min_score)
        
        return {
            "candidates": candidates,
            "total": len(candidates),
            "trait_name": trait_name,
            "min_score": min_score,
            "message": f"æ‰¾åˆ° {len(candidates)} ä½ {trait_name} >= {min_score} çš„å€™é¸äºº"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/session/{session_id}/context")
async def get_session_context(session_id: str):
    """
    ç²å–æœƒè©±ä¸Šä¸‹æ–‡è³‡è¨Š
    
    è¿”å›ç•¶å‰æœƒè©±çš„ï¼š
    - å°è©±æ­·å²
    - ç•¶å‰å€™é¸äºº
    - å€™é¸äººåˆ—è¡¨
    - ä¸Šä¸‹æ–‡æ‘˜è¦
    """
    try:
        context = conversation_manager.get_or_create_session(session_id)
        
        return {
            "session_id": session_id,
            "message_count": len(context.messages),
            "current_candidate": context.current_candidate,
            "candidates_count": len(context.current_candidates),
            "last_intent": context.last_intent,
            "context_summary": context.get_context_summary(),
            "conversation_history": context.get_conversation_history(limit=5)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/session/{session_id}")
async def clear_session(session_id: str):
    """æ¸…é™¤æœƒè©±ä¸Šä¸‹æ–‡"""
    try:
        if session_id in conversation_manager.sessions:
            conversation_manager.sessions[session_id].clear()
            return {
                "success": True,
                "message": f"æœƒè©± {session_id} å·²æ¸…é™¤"
            }
        else:
            return {
                "success": False,
                "message": f"æœƒè©± {session_id} ä¸å­˜åœ¨"
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/candidates/{candidate_id}/analyze")
async def analyze_candidate(candidate_id: int):
    """
    åˆ†æå€™é¸äººç‰¹è³ª - ä½¿ç”¨ LLM ç”Ÿæˆæ·±åº¦åˆ†æ
    
    è¿”å›ï¼š
    - personality_traits: æ€§æ ¼ç‰¹å¾µ
    - core_strengths: æ ¸å¿ƒå„ªå‹¢
    - suitable_positions: é©åˆè·ä½
    - work_style: å·¥ä½œé¢¨æ ¼
    - team_role: åœ˜éšŠè§’è‰²
    - development_suggestions: ç™¼å±•å»ºè­°
    - interview_focus: é¢è©¦é‡é»
    - summary: ä¸€å¥è©±ç¸½çµ
    """
    try:
        # 1. ç²å–å€™é¸äººè³‡æ–™
        engine = TalentSearchEngine()
        conn = engine.conn
        cursor = conn.cursor()
        
        sql = """
            SELECT 
                tiv.id,
                tiv.name,
                tiv.email,
                tiv.phone,
                tiv.company,
                tiv.position,
                tp.name as project_name,
                tpr.trait_results,
                tpr.category_results
            FROM test_project_result tpr
            INNER JOIN test_invitation ti ON tpr.test_invitation_id = ti.id
            INNER JOIN test_invitee tiv ON ti.invitee_id = tiv.id
            INNER JOIN test_project tp ON tpr.test_project_id = tp.id
            WHERE tiv.id = %s
              AND tpr.trait_results IS NOT NULL
            LIMIT 1;
        """
        
        cursor.execute(sql, (candidate_id,))
        row = cursor.fetchone()
        cursor.close()
        
        if not row:
            raise HTTPException(status_code=404, detail="å€™é¸äººä¸å­˜åœ¨æˆ–æ²’æœ‰æ¸¬é©—çµæœ")
        
        # 2. æº–å‚™å€™é¸äººè³‡æ–™
        trait_results = enrich_trait_results(row[7] if row[7] else {})
        
        candidate = {
            'id': row[0],
            'name': row[1],
            'email': row[2],
            'phone': row[3],
            'company': row[4],
            'position': row[5],
            'project_name': row[6],
            'trait_results': trait_results,
            'category_results': row[8] if row[8] else {}
        }
        
        # 3. ä½¿ç”¨ LLM åˆ†æ
        analysis_service = TalentAnalysisService(
            api_key=LLM_CONFIG['api_key'],
            api_endpoint=LLM_CONFIG['endpoint'],
            model=LLM_CONFIG['model']
        )
        
        analysis_result = await analysis_service.analyze_candidate(candidate)
        
        if not analysis_result['success']:
            raise HTTPException(status_code=500, detail=analysis_result.get('error', 'åˆ†æå¤±æ•—'))
        
        # 4. è¿”å›åˆ†æçµæœ
        return {
            'candidate_id': candidate_id,
            'candidate_name': candidate['name'],
            'analysis': analysis_result['analysis'],
            'raw_traits': analysis_result.get('raw_traits', {}),
            'formatted_text': analysis_service.format_analysis_for_display(analysis_result)
        }
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"åˆ†æéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == '__main__':
    print("=" * 60)
    print("äººæ‰èŠå¤©æœç´¢ API v2.1 - æ™ºèƒ½æœç´¢ç‰ˆ")
    print("=" * 60)
    print("âœ¨ æ–°ç‰¹æ€§:")
    print("  â€¢ ğŸ¤– LLM æ™ºèƒ½æŸ¥è©¢åˆ†æ")
    print("  â€¢ ğŸ¯ æ ¹æ“šç‰¹è³ªç²¾æº–åŒ¹é…")
    print("  â€¢ ğŸ“Š ä½¿ç”¨ test_project_result è¡¨ï¼ˆ27 ç­†æ•¸æ“šï¼‰")
    print("  â€¢ ğŸ‡¨ğŸ‡³ æ•´åˆ trait è¡¨é¡¯ç¤ºä¸­æ–‡åç¨±")
    print("  â€¢ ğŸ“ˆ æ™ºèƒ½åŒ¹é…åˆ†æ•¸è¨ˆç®—")
    print("=" * 60)
    print("å•Ÿå‹•æœå‹™...")
    print("API æ–‡æª”: http://localhost:8000/docs")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
