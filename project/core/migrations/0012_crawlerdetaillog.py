# Generated by Django 4.2.20 on 2025-08-01 02:19

from django.db import migrations, models
import django.db.models.deletion
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ('core', '0011_alter_testprojectassignment_test_project'),
    ]

    operations = [
        migrations.CreateModel(
            name='CrawlerDetailLog',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('invitee_name', models.CharField(max_length=100, verbose_name='受測人姓名')),
                ('invitee_email', models.EmailField(max_length=254, verbose_name='受測人信箱')),
                ('test_project_name', models.CharField(max_length=200, verbose_name='測驗項目')),
                ('status', models.CharField(choices=[('success', '成功'), ('failed', '失敗'), ('skipped', '跳過')], max_length=20, verbose_name='爬取狀態')),
                ('error_message', models.TextField(blank=True, verbose_name='錯誤訊息')),
                ('error_details', models.JSONField(blank=True, default=dict, verbose_name='詳細錯誤資訊')),
                ('attempt_count', models.IntegerField(default=1, verbose_name='嘗試次數')),
                ('execution_time', models.FloatField(blank=True, null=True, verbose_name='執行時間(秒)')),
                ('data_found', models.BooleanField(default=False, verbose_name='是否找到資料')),
                ('crawled_data_size', models.IntegerField(default=0, verbose_name='爬取資料大小')),
                ('executed_at', models.DateTimeField(default=django.utils.timezone.now, verbose_name='執行時間')),
                ('crawler_log', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='detail_logs', to='core.crawlerlog', verbose_name='爬蟲日誌')),
                ('test_invitation', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='core.testinvitation', verbose_name='測驗邀請')),
            ],
            options={
                'verbose_name': '爬蟲詳細日誌',
                'verbose_name_plural': '爬蟲詳細日誌',
                'db_table': 'crawler_detail_logs',
                'ordering': ['-executed_at'],
            },
        ),
    ]
